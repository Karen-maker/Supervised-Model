{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Classification Model Development\n",
    "<br>\n",
    "Karen Itzell Larios Inzunza <br>\n",
    "\n",
    "DAT-5303-FMsBA2 Hult International Business School<br><br><br>\n",
    "\n",
    "<h2>Introduction: </h2> Continuing with the analysis of the database of Apprentice Chef in order to understand their new cross selling promotion, where subscribers receive a half bottle of wine from a local California vineyard every Wednesday. The insights seen through this analysis come from the development of a classification model by using different variables that are used to see the success of this cross selling promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Exploration of the Data\n",
    "\n",
    "The very first thing is to import the necessary libraries, set the printing options and load the dataset.\n",
    "The data could be checked just to make sure that it has loaded correctly, also the information to see what type of data it is and if it's necessary to make some transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>CROSS_SELL_SUCCESS</th>\n",
       "      <th>TOTAL_MEALS_ORDERED</th>\n",
       "      <th>UNIQUE_MEALS_PURCH</th>\n",
       "      <th>CONTACTS_W_CUSTOMER_SERVICE</th>\n",
       "      <th>PRODUCT_CATEGORIES_VIEWED</th>\n",
       "      <th>AVG_TIME_PER_SITE_VISIT</th>\n",
       "      <th>MOBILE_NUMBER</th>\n",
       "      <th>CANCELLATIONS_BEFORE_NOON</th>\n",
       "      <th>CANCELLATIONS_AFTER_NOON</th>\n",
       "      <th>TASTES_AND_PREFERENCES</th>\n",
       "      <th>PC_LOGINS</th>\n",
       "      <th>MOBILE_LOGINS</th>\n",
       "      <th>WEEKLY_PLAN</th>\n",
       "      <th>EARLY_DELIVERIES</th>\n",
       "      <th>LATE_DELIVERIES</th>\n",
       "      <th>PACKAGE_LOCKER</th>\n",
       "      <th>REFRIGERATED_LOCKER</th>\n",
       "      <th>AVG_PREP_VID_TIME</th>\n",
       "      <th>LARGEST_ORDER_SIZE</th>\n",
       "      <th>MASTER_CLASSES_ATTENDED</th>\n",
       "      <th>MEDIAN_MEAL_RATING</th>\n",
       "      <th>AVG_CLICKS_PER_VISIT</th>\n",
       "      <th>TOTAL_PHOTOS_VIEWED</th>\n",
       "      <th>unknown</th>\n",
       "      <th>potential_male</th>\n",
       "      <th>potential_female</th>\n",
       "      <th>junk</th>\n",
       "      <th>personal</th>\n",
       "      <th>professional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1946.00</td>\n",
       "      <td>1946.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2107.29</td>\n",
       "      <td>0.68</td>\n",
       "      <td>74.63</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.98</td>\n",
       "      <td>5.38</td>\n",
       "      <td>99.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.48</td>\n",
       "      <td>11.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.11</td>\n",
       "      <td>150.56</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.79</td>\n",
       "      <td>13.51</td>\n",
       "      <td>106.43</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1138.29</td>\n",
       "      <td>0.47</td>\n",
       "      <td>55.31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.28</td>\n",
       "      <td>3.04</td>\n",
       "      <td>62.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>13.57</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>49.45</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.33</td>\n",
       "      <td>181.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>131.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1350.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>114.40</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1740.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>94.16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.60</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2670.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>117.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>173.78</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8793.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>493.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1645.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>564.20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       REVENUE  CROSS_SELL_SUCCESS  TOTAL_MEALS_ORDERED  UNIQUE_MEALS_PURCH  CONTACTS_W_CUSTOMER_SERVICE  PRODUCT_CATEGORIES_VIEWED  AVG_TIME_PER_SITE_VISIT  MOBILE_NUMBER  CANCELLATIONS_BEFORE_NOON  CANCELLATIONS_AFTER_NOON  TASTES_AND_PREFERENCES  PC_LOGINS  MOBILE_LOGINS  WEEKLY_PLAN  EARLY_DELIVERIES  LATE_DELIVERIES  PACKAGE_LOCKER  REFRIGERATED_LOCKER  AVG_PREP_VID_TIME  LARGEST_ORDER_SIZE  MASTER_CLASSES_ATTENDED  MEDIAN_MEAL_RATING  AVG_CLICKS_PER_VISIT  TOTAL_PHOTOS_VIEWED  unknown  potential_male  potential_female    junk  personal  professional\n",
       "count  1946.00             1946.00              1946.00              1946.0                      1946.00                    1946.00                  1946.00        1946.00                    1946.00                   1946.00                 1946.00    1946.00        1946.00      1946.00           1946.00          1946.00         1946.00              1946.00            1946.00             1946.00                  1946.00             1946.00               1946.00              1946.00  1946.00         1946.00           1946.00  1946.0   1946.00       1946.00\n",
       "mean   2107.29                0.68                74.63                 4.9                         6.98                       5.38                    99.60           0.88                       1.40                      0.17                    0.71       5.52           1.48        11.33              1.49             2.97            0.36                 0.11             150.56                4.44                     0.60                2.79                 13.51               106.43     0.71            0.21              0.08     0.2      0.44          0.36\n",
       "std    1138.29                0.47                55.31                 2.5                         2.28                       3.04                    62.34           0.33                       1.55                      0.43                    0.45       0.58           0.53        13.57              2.32             2.74            0.48                 0.32              49.45                1.55                     0.64                0.76                  2.33               181.01     0.45            0.41              0.26     0.4      0.50          0.48\n",
       "min     131.00                0.00                11.00                 1.0                         1.00                       1.00                    10.33           0.00                       0.00                      0.00                    0.00       4.00           0.00         0.00              0.00             0.00            0.00                 0.00              33.40                1.00                     0.00                1.00                  5.00                 0.00     0.00            0.00              0.00     0.0      0.00          0.00\n",
       "25%    1350.00                0.00                39.00                 3.0                         5.00                       3.00                    72.00           1.00                       0.00                      0.00                    0.00       5.00           1.00         1.00              0.00             1.00            0.00                 0.00             114.40                3.00                     0.00                2.00                 12.00                 0.00     0.00            0.00              0.00     0.0      0.00          0.00\n",
       "50%    1740.00                1.00                60.00                 5.0                         7.00                       5.00                    94.16           1.00                       1.00                      0.00                    1.00       6.00           1.00         7.00              0.00             2.00            0.00                 0.00             145.60                4.00                     1.00                3.00                 13.00                 0.00     1.00            0.00              0.00     0.0      0.00          0.00\n",
       "75%    2670.00                1.00                95.00                 7.0                         8.00                       8.00                   117.29           1.00                       2.00                      0.00                    1.00       6.00           2.00        13.00              3.00             4.00            1.00                 0.00             173.78                5.00                     1.00                3.00                 15.00               174.00     1.00            0.00              0.00     0.0      1.00          1.00\n",
       "max    8793.75                1.00               493.00                19.0                        18.00                      10.00                  1645.60           1.00                      13.00                      3.00                    1.00       7.00           3.00        52.00              9.00            19.00            1.00                 1.00             564.20               11.00                     3.00                5.00                 19.00              1600.00     1.00            1.00              1.00     1.0      1.00          1.00"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import random            as rand                     # random number gen\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.utils import resample                   # to balance the model\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO                             # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus \n",
    "from sklearn.model_selection import RandomizedSearchCV  # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                 # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# specifying the path and file name\n",
    "file = './Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "Apprentice_Chef = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# checking the file\n",
    "Apprentice_Chef.describe().round(decimals=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we load the data we need to start to start analyzing the variables. This time the predicted outcome is the variable of CROSS_SELL_SUCCESS. Is a classification variable that states if a customer has subscribed to their promotion or not. We create a histogram and do a value count to know the exact number of subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CROSS_SELL_SUCCESS\n",
       "1    1321\n",
       "0     625\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.displot(data = Apprentice_Chef,\n",
    "            x = 'CROSS_SELL_SUCCESS',\n",
    "            height = 5,\n",
    "            aspect = 2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Apprentice_Chef.value_counts('CROSS_SELL_SUCCESS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is unbalanced, there are more 1's than 0's and this can cause a problem when trying to build a classification model. First, we will run a normal regression using the data as it is, to check the score, and from there do feature engineering and hyperparameter tuning to increase the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>User-Defined Functions</strong><br>\n",
    "Defining the functions that will be used all through the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width)\n",
    "    \n",
    "    return img\n",
    "\n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# display_tree\n",
    "########################################\n",
    "def display_tree(tree, feature_df, height = 500, width = 800, export = False):\n",
    "    \"\"\"\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    tree       : fitted tree model object\n",
    "        fitted CART model to visualized\n",
    "    feature_df : DataFrame\n",
    "        DataFrame of explanatory features (used to generate labels)\n",
    "    height     : int, default 500\n",
    "        height in pixels to which to constrain image in html\n",
    "    width      : int, default 800\n",
    "        width in pixels to which to constrain image in html\n",
    "    export     : bool, defalut False\n",
    "        whether or not to export the tree as a .png file\n",
    "    \"\"\"\n",
    "\n",
    "    # visualizing the tree\n",
    "    dot_data = StringIO()\n",
    "\n",
    "    \n",
    "    # exporting tree to graphviz\n",
    "    export_graphviz(decision_tree      = tree,\n",
    "                    out_file           = dot_data,\n",
    "                    filled             = True,\n",
    "                    rounded            = True,\n",
    "                    special_characters = True,\n",
    "                    feature_names      = feature_df.columns)\n",
    "\n",
    "\n",
    "    # declaring a graph object\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "\n",
    "    # creating image\n",
    "    img = Image(graph.create_png(),\n",
    "                height = height,\n",
    "                width  = width,\n",
    "                unconfined = True)\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('./analysis_images/Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>Organizing the Variables</h2><br>\n",
    "Separating male from female, as well as, the different email addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gender_guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing gender based on (given) name\n",
    "\n",
    "#import gender_guesser.detector as gender\n",
    "\n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in Apprentice_Chef['FIRST_NAME']:\n",
    "#    guess = gender.Detector().get_gender(name)\n",
    "#    print(guess)\n",
    "#    placeholder_lst.append(guess)\n",
    "\n",
    "\n",
    "# converting list into a series\n",
    "#Apprentice_Chef['gender_guess'] = pd.Series(placeholder_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating with original DataFrame\n",
    "#Apprentice_Chef['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# checking results\n",
    "#Apprentice_Chef['domain_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummies for Emails\n",
    "#dummy_Email      = pd.get_dummies(Apprentice_Chef['domain_group'])\n",
    "\n",
    "#Dropping EMAIL and domain_group from apprentice_chef\n",
    "#Apprentice_Chef        = Apprentice_Chef.drop('gender_guess', axis = 1)\n",
    "#Apprentice_Chef        = Apprentice_Chef.drop('domain_group', axis = 1)\n",
    "\n",
    "#Joining the dummies to apprentice_chef\n",
    "#Apprentice_Chef       = Apprentice_Chef.join([dummy_Email])\n",
    "\n",
    "\n",
    "# saving new columns\n",
    "#new_columns = Apprentice_Chef.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the columns to create a new one joining all the potential males\n",
    "#Apprentice_Chef[\"potential_male\"] = Apprentice_Chef[\"male\"] + Apprentice_Chef[\"mostly_male\"] + Apprentice_Chef[\"andy\"] \n",
    "\n",
    "#Combining the columns to create a new one joining all the potential females\n",
    "#Apprentice_Chef[\"potential_female\"] = Apprentice_Chef[\"female\"] + Apprentice_Chef[\"mostly_female\"]\n",
    "\n",
    "#Dropping andy, female, male, mostly_female, mostly_male\n",
    "#Apprentice_Chef = Apprentice_Chef.drop(['andy', 'female', 'male', 'mostly_female', 'mostly_male'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with Categorical Data\n",
    "#Splitting Emails\n",
    "\n",
    "# STEP 1: splitting personal emails\n",
    "\n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "#for index, col in Apprentice_Chef.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "#    split_email = Apprentice_Chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "#    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "#email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "#email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Personal, Professional and Junk Emails\n",
    "#personal_email_domains      = ['@gmail.com',\n",
    "#                               '@yahoo.com',\n",
    "#                               '@protonmail.com']\n",
    "\n",
    "#professional_email_domains  = ['@mmm.com',\n",
    "#                               '@amex.com',\n",
    "#                               '@apple.com',\n",
    "#                               '@boeing.com',\n",
    "#                               '@caterpillar.com',\n",
    "#                               '@chevron.com',\n",
    "#                               '@cisco.com',\n",
    "#                               '@cocacola.com',\n",
    "#                               '@disney.com',\n",
    "#                               '@dupont.com',\n",
    "#                               '@exxon.com',\n",
    "#                               '@ge.org',\n",
    "#                               '@goldmansacs.com',\n",
    "#                               '@homedepot.com',\n",
    "#                               '@ibm.com',\n",
    "#                               '@intel.com',\n",
    "#                               '@jnj.com',\n",
    "#                               '@jpmorgan.com',\n",
    "#                               '@mcdonalds.com',\n",
    "#                               '@merck.com',\n",
    "#                               '@microsoft.com',\n",
    "#                               '@nike.com',\n",
    "#                               '@pfizer.com',\n",
    "#                               '@pg.com',\n",
    "#                               '@travelers.com',\n",
    "#                               '@unitedtech.com',\n",
    "#                               '@unitedhealth.com',\n",
    "#                               '@verizon.com',\n",
    "#                               '@visa.com',\n",
    "#                               '@walmart.com']\n",
    "\n",
    "#junk_email_domains          = ['@me.com',\n",
    "#                               '@aol.com',\n",
    "#                               '@hotmail.com',\n",
    "#                               '@live.com',\n",
    "#                               '@msn.com',\n",
    "#                               '@passport.com']\n",
    "\n",
    "\n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "#for domain in email_df[1]:\n",
    "#        if '@' + domain in personal_email_domains:\n",
    "#            placeholder_lst.append('personal')\n",
    "            \n",
    "#        elif '@' + domain in professional_email_domains:\n",
    "#            placeholder_lst.append('professional')\n",
    "           \n",
    "#        elif '@' + domain in junk_email_domains:\n",
    "#            placeholder_lst.append('junk')\n",
    "            \n",
    "#        else:\n",
    "#            print('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "#Apprentice_Chef['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# checking results\n",
    "#Apprentice_Chef['domain_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummies for Emails\n",
    "#dummy_Email      = pd.get_dummies(Apprentice_Chef['domain_group'])\n",
    "\n",
    "#Dropping EMAIL and domain_group from apprentice_chef\n",
    "#Apprentice_Chef        = Apprentice_Chef.drop('EMAIL', axis = 1)\n",
    "#Apprentice_Chef        = Apprentice_Chef.drop('domain_group', axis = 1)\n",
    "\n",
    "#Joining the dummies to apprentice_chef\n",
    "#Apprentice_Chef       = Apprentice_Chef.join([dummy_Email])\n",
    "\n",
    "\n",
    "# saving new columns\n",
    "#new_columns = Apprentice_Chef.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results\n",
    "#Apprentice_Chef.to_excel('./Apprentice_Chef_Dataset.xlsx',\n",
    "#                 index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                           No\t\tYes\n",
      "                      ---------------------\n",
      "Avg Time per Site Visit        | 87\t\t1859\n",
      "Avg Prep Video Time            | 930\t\t1016\n",
      "Photos Viewed                  | 66\t\t1880\n",
      "Total Meals Ordered            | 135\t\t1811\n",
      "Unique Meals Purchased         | 12\t\t1934\n",
      "Contact with Customer Service  | 678\t\t1268\n",
      "Products Viewed                | 287\t\t1659\n",
      "Cancellations before noon      | 667\t\t1279\n",
      "Cancellations after noon       | 1667\t\t279\n",
      "Mobile Logins                  | 931\t\t1015\n",
      "PC Logins                      | 1946\t\t0\n",
      "Weekly Plan                    | 131\t\t1815\n",
      "Early Deliveries               | 1167\t\t779\n",
      "Late Deliveries                | 319\t\t1627\n",
      "Largest Order Size             | 407\t\t1539\n",
      "Median Meal Rating             | 1360\t\t586\n",
      "Average Clicks per Visit       | 1940\t\t6\n",
      "Master Class Attended          | 932\t\t1014\n",
      "Revenue                        | 247\t\t1699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting the number of outliers using the continuos variables\n",
    "#Setting thresholds based on the previous scatterplots and the standard deviations of each variable\n",
    "timeonsitevisit_zeroes   = len(Apprentice_Chef['AVG_TIME_PER_SITE_VISIT'][Apprentice_Chef['AVG_TIME_PER_SITE_VISIT'] > 186])\n",
    "prepvideotime_zeroes  = len(Apprentice_Chef['AVG_PREP_VID_TIME'][Apprentice_Chef['AVG_PREP_VID_TIME'] > 148])\n",
    "photos_zeroes      = len(Apprentice_Chef['TOTAL_PHOTOS_VIEWED'][Apprentice_Chef['TOTAL_PHOTOS_VIEWED'] > 543])\n",
    "mealsordered_zeroes = len(Apprentice_Chef['TOTAL_MEALS_ORDERED'][Apprentice_Chef['TOTAL_MEALS_ORDERED'] > 165])\n",
    "uniquemeals_zeroes   = len(Apprentice_Chef['UNIQUE_MEALS_PURCH'][Apprentice_Chef['UNIQUE_MEALS_PURCH'] > 10])\n",
    "customerservice_zeroes  = len(Apprentice_Chef['CONTACTS_W_CUSTOMER_SERVICE'][Apprentice_Chef['CONTACTS_W_CUSTOMER_SERVICE'] > 7])\n",
    "productsviewed_zeroes      = len(Apprentice_Chef['PRODUCT_CATEGORIES_VIEWED'][Apprentice_Chef['PRODUCT_CATEGORIES_VIEWED'] > 9])\n",
    "cancellationsbefore_zeroes = len(Apprentice_Chef['CANCELLATIONS_BEFORE_NOON'][Apprentice_Chef['CANCELLATIONS_BEFORE_NOON'] == 0])\n",
    "cancellationsafter_zeroes = len(Apprentice_Chef['CANCELLATIONS_AFTER_NOON'][Apprentice_Chef['CANCELLATIONS_AFTER_NOON'] == 0])\n",
    "mobilelogins_zeroes = len(Apprentice_Chef['MOBILE_LOGINS'][Apprentice_Chef['MOBILE_LOGINS'] > 1])\n",
    "pclogins_zeroes = len(Apprentice_Chef['PC_LOGINS'][Apprentice_Chef['PC_LOGINS'] > 1])\n",
    "weeklyplan_zeroes = len(Apprentice_Chef['WEEKLY_PLAN'][Apprentice_Chef['WEEKLY_PLAN'] > 41])\n",
    "earlydelivery_zeroes = len(Apprentice_Chef['EARLY_DELIVERIES'][Apprentice_Chef['EARLY_DELIVERIES'] == 0])\n",
    "latedelivery_zeroes = len(Apprentice_Chef['LATE_DELIVERIES'][Apprentice_Chef['LATE_DELIVERIES'] == 0])\n",
    "largestorder_zeroes = len(Apprentice_Chef['LARGEST_ORDER_SIZE'][Apprentice_Chef['LARGEST_ORDER_SIZE'] > 5])\n",
    "medianmealrating_zeroes = len(Apprentice_Chef['MEDIAN_MEAL_RATING'][Apprentice_Chef['MEDIAN_MEAL_RATING'] >2 ])\n",
    "clickspervisit_zeroes = len(Apprentice_Chef['AVG_CLICKS_PER_VISIT'][Apprentice_Chef['AVG_CLICKS_PER_VISIT'] >7 ])\n",
    "classattended_zeroes = len(Apprentice_Chef['MASTER_CLASSES_ATTENDED'][Apprentice_Chef['MASTER_CLASSES_ATTENDED'] == 0])\n",
    "revenue_zeroes = len(Apprentice_Chef['REVENUE'][Apprentice_Chef['REVENUE'] > 3414])\n",
    "\n",
    "\n",
    "# printing a table of the results\n",
    "print(f\"\"\"\n",
    "                           No\\t\\tYes\n",
    "                      ---------------------\n",
    "Avg Time per Site Visit        | {timeonsitevisit_zeroes}\\t\\t{len(Apprentice_Chef) - timeonsitevisit_zeroes}\n",
    "Avg Prep Video Time            | {prepvideotime_zeroes}\\t\\t{len(Apprentice_Chef) - prepvideotime_zeroes}\n",
    "Photos Viewed                  | {photos_zeroes}\\t\\t{len(Apprentice_Chef) - photos_zeroes}\n",
    "Total Meals Ordered            | {mealsordered_zeroes}\\t\\t{len(Apprentice_Chef) - mealsordered_zeroes}\n",
    "Unique Meals Purchased         | {uniquemeals_zeroes}\\t\\t{len(Apprentice_Chef) - uniquemeals_zeroes}\n",
    "Contact with Customer Service  | {customerservice_zeroes}\\t\\t{len(Apprentice_Chef) - customerservice_zeroes}\n",
    "Products Viewed                | {productsviewed_zeroes}\\t\\t{len(Apprentice_Chef) - productsviewed_zeroes}\n",
    "Cancellations before noon      | {cancellationsbefore_zeroes}\\t\\t{len(Apprentice_Chef) - cancellationsbefore_zeroes}\n",
    "Cancellations after noon       | {cancellationsafter_zeroes}\\t\\t{len(Apprentice_Chef) - cancellationsafter_zeroes}\n",
    "Mobile Logins                  | {mobilelogins_zeroes}\\t\\t{len(Apprentice_Chef) - mobilelogins_zeroes}\n",
    "PC Logins                      | {pclogins_zeroes}\\t\\t{len(Apprentice_Chef) - pclogins_zeroes}\n",
    "Weekly Plan                    | {weeklyplan_zeroes}\\t\\t{len(Apprentice_Chef) - weeklyplan_zeroes}\n",
    "Early Deliveries               | {earlydelivery_zeroes}\\t\\t{len(Apprentice_Chef) - earlydelivery_zeroes}\n",
    "Late Deliveries                | {latedelivery_zeroes}\\t\\t{len(Apprentice_Chef) - latedelivery_zeroes}\n",
    "Largest Order Size             | {largestorder_zeroes}\\t\\t{len(Apprentice_Chef) - largestorder_zeroes}\n",
    "Median Meal Rating             | {medianmealrating_zeroes}\\t\\t{len(Apprentice_Chef) - medianmealrating_zeroes}\n",
    "Average Clicks per Visit       | {clickspervisit_zeroes}\\t\\t{len(Apprentice_Chef) - clickspervisit_zeroes}\n",
    "Master Class Attended          | {classattended_zeroes}\\t\\t{len(Apprentice_Chef) - classattended_zeroes}\n",
    "Revenue                        | {revenue_zeroes}\\t\\t{len(Apprentice_Chef) - revenue_zeroes}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg time per Site Visit and Photos Viewed were removed since they doesn't follow the rule for flag-based features\n",
    "\n",
    "# dummy variable for ordering total meals within the range\n",
    "Apprentice_Chef['TOTAL_MEALS_ORDERED_range']   = 0\n",
    "Apprentice_Chef['AVG_PREP_VID_TIME_range'] = 0\n",
    "Apprentice_Chef['CONTACTS_W_CUSTOMER_SERVICE_range'] = 0\n",
    "Apprentice_Chef['PRODUCT_CATEGORIES_VIEWED_range']   = 0\n",
    "Apprentice_Chef['CANCELLATIONS_BEFORE_NOON_range']   = 0\n",
    "Apprentice_Chef['CANCELLATIONS_AFTER_NOON_range']    = 0\n",
    "Apprentice_Chef['MOBILE_LOGINS_range']               = 0\n",
    "Apprentice_Chef['WEEKLY_PLAN_range']                 = 0\n",
    "Apprentice_Chef['EARLY_DELIVERIES_range']            = 0\n",
    "Apprentice_Chef['LATE_DELIVERIES_range']             = 0\n",
    "Apprentice_Chef['LARGEST_ORDER_SIZE_range']          = 0\n",
    "Apprentice_Chef['MEDIAN_MEAL_RATING_range']          = 0\n",
    "Apprentice_Chef['MASTER_CLASSES_ATTENDED_range']     = 0\n",
    "Apprentice_Chef['REVENUE_range'] = 0\n",
    "\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in Apprentice_Chef.iterrows():\n",
    "    \n",
    "    # TOTAL_MEALS_ORDERED\n",
    "    if Apprentice_Chef.loc[index, 'TOTAL_MEALS_ORDERED'] < 165:\n",
    "        Apprentice_Chef.loc[index, 'TOTAL_MEALS_ORDERED_range'] = 1\n",
    "        \n",
    "    \n",
    "    # AVG_PREP_VID_TIME\n",
    "    if Apprentice_Chef.loc[index, 'AVG_PREP_VID_TIME'] < 148:\n",
    "        Apprentice_Chef.loc[index, 'AVG_PREP_VID_TIME_range'] = 1\n",
    "        \n",
    "    # CONTACTS_W_CUSTOMER_SERVICE\n",
    "    if Apprentice_Chef.loc[index, \"CONTACTS_W_CUSTOMER_SERVICE\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'CONTACTS_W_CUSTOMER_SERVICE_range'] = 1\n",
    "        \n",
    "        \n",
    "    # PRODUCT_CATEGORIES_VIEWED\n",
    "    if Apprentice_Chef.loc[index, \"PRODUCT_CATEGORIES_VIEWED\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'PRODUCT_CATEGORIES_VIEWED_range'] = 1\n",
    "\n",
    "    # CANCELLATIONS_BEFORE_NOON\n",
    "    if Apprentice_Chef.loc[index, \"CANCELLATIONS_BEFORE_NOON\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'CANCELLATIONS_BEFORE_NOON_range'] = 1\n",
    "        \n",
    "    # CANCELLATIONS_AFTER_NOON\n",
    "    if Apprentice_Chef.loc[index, \"CANCELLATIONS_AFTER_NOON\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'CANCELLATIONS_AFTER_NOON_range'] = 1\n",
    "        \n",
    "    # MOBILE_LOGINS\n",
    "    if Apprentice_Chef.loc[index, \"MOBILE_LOGINS\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'MOBILE_LOGINS_range'] = 1\n",
    "               \n",
    "    # WEEKLY_PLAN\n",
    "    if Apprentice_Chef.loc[index, \"WEEKLY_PLAN\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'WEEKLY_PLAN_range'] = 1\n",
    "        \n",
    "    # EARLY_DELIVERIES\n",
    "    if Apprentice_Chef.loc[index, \"EARLY_DELIVERIES\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'EARLY_DELIVERIES_range'] = 1\n",
    "        \n",
    "    # LATE_DELIVERIES\n",
    "    if Apprentice_Chef.loc[index, \"LATE_DELIVERIES\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'LATE_DELIVERIES_range'] = 1\n",
    "        \n",
    "    # LARGEST_ORDER_SIZE\n",
    "    if Apprentice_Chef.loc[index, \"LARGEST_ORDER_SIZE\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'LARGEST_ORDER_SIZE_range'] = 1\n",
    "\n",
    "    # MEDIAN_MEAL_RATING\n",
    "    if Apprentice_Chef.loc[index, \"MEDIAN_MEAL_RATING\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'MEDIAN_MEAL_RATING_range'] = 1\n",
    "        \n",
    "    # MASTER_CLASSES_ATTENDED\n",
    "    if Apprentice_Chef.loc[index, \"MASTER_CLASSES_ATTENDED\"] > 0:\n",
    "        Apprentice_Chef.loc[index, 'MASTER_CLASSES_ATTENDED_range'] = 1\n",
    "        \n",
    "    #Revenue\n",
    "    if Apprentice_Chef.loc[index, \"REVENUE\"] < 3414:\n",
    "        Apprentice_Chef.loc[index, 'REVENUE_range'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "<h4>Correlation Analysis</h4>\n",
    "Checking the correlation between the variables to see the significance towards the desired output, CROSS_SELL_SUCCESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CROSS_SELL_SUCCESS                   1.00\n",
       "professional                         0.19\n",
       "CANCELLATIONS_BEFORE_NOON            0.16\n",
       "CANCELLATIONS_BEFORE_NOON_range      0.14\n",
       "potential_male                       0.11\n",
       "MOBILE_NUMBER                        0.10\n",
       "TASTES_AND_PREFERENCES               0.08\n",
       "REFRIGERATED_LOCKER                  0.07\n",
       "MASTER_CLASSES_ATTENDED_range        0.05\n",
       "PACKAGE_LOCKER                       0.04\n",
       "CONTACTS_W_CUSTOMER_SERVICE          0.04\n",
       "MASTER_CLASSES_ATTENDED              0.04\n",
       "personal                             0.04\n",
       "PC_LOGINS                            0.04\n",
       "AVG_PREP_VID_TIME                    0.03\n",
       "MEDIAN_MEAL_RATING                   0.03\n",
       "LARGEST_ORDER_SIZE                   0.02\n",
       "TOTAL_MEALS_ORDERED_range            0.02\n",
       "EARLY_DELIVERIES                     0.02\n",
       "TOTAL_PHOTOS_VIEWED                  0.01\n",
       "AVG_TIME_PER_SITE_VISIT              0.01\n",
       "MOBILE_LOGINS_range                  0.01\n",
       "TOTAL_MEALS_ORDERED                  0.01\n",
       "LATE_DELIVERIES                      0.01\n",
       "PRODUCT_CATEGORIES_VIEWED            0.00\n",
       "UNIQUE_MEALS_PURCH                   0.00\n",
       "REVENUE_range                       -0.00\n",
       "LATE_DELIVERIES_range                0.00\n",
       "REVENUE                              0.00\n",
       "WEEKLY_PLAN                         -0.01\n",
       "EARLY_DELIVERIES_range              -0.01\n",
       "WEEKLY_PLAN_range                   -0.02\n",
       "AVG_CLICKS_PER_VISIT                -0.04\n",
       "unknown                             -0.04\n",
       "AVG_PREP_VID_TIME_range             -0.04\n",
       "MOBILE_LOGINS                       -0.05\n",
       "CANCELLATIONS_AFTER_NOON            -0.05\n",
       "CANCELLATIONS_AFTER_NOON_range      -0.05\n",
       "potential_female                    -0.10\n",
       "junk                                -0.28\n",
       "CONTACTS_W_CUSTOMER_SERVICE_range     NaN\n",
       "PRODUCT_CATEGORIES_VIEWED_range       NaN\n",
       "LARGEST_ORDER_SIZE_range              NaN\n",
       "MEDIAN_MEAL_RATING_range              NaN\n",
       "Name: CROSS_SELL_SUCCESS, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = Apprentice_Chef.corr(method='pearson').round(decimals=2)\n",
    "\n",
    "df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation of the variables are not so high.</br>\n",
    "<br>\n",
    "The highest correlation is the junk email which is a negative correlation. The highest positive is professional email. We need deeper analysis to see if this variables can create an impact on CROSS_SELL_SUCCESS.\n",
    "<br>\n",
    "<br>\n",
    "Next, we are going to create a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "Apprentice_Chef_data = Apprentice_Chef.drop(['CROSS_SELL_SUCCESS', 'NAME', 'FIRST_NAME', 'FAMILY_NAME', ], axis=1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "Apprentice_Chef_response = Apprentice_Chef.loc[:, 'CROSS_SELL_SUCCESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            Apprentice_Chef_data,\n",
    "            Apprentice_Chef_response,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = Apprentice_Chef_response)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "Apprentice_Chef_train = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.68\n",
      "0    0.32\n",
      "Name: CROSS_SELL_SUCCESS, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.68\n",
      "0    0.32\n",
      "Name: CROSS_SELL_SUCCESS, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>2. Analyzing the models</h2><br>\n",
    "<h4>Logistic Regression</h4>\n",
    "The first model is just using the variable that has the highest correlation, junk email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.590544\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1457</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jan 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.05958</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:37</td>      <th>  Log-Likelihood:    </th> <td> -861.60</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.483e-25</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.0659</td> <td>    0.067</td> <td>   15.922</td> <td> 0.000</td> <td>    0.935</td> <td>    1.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>      <td>   -1.4166</td> <td>    0.137</td> <td>  -10.331</td> <td> 0.000</td> <td>   -1.685</td> <td>   -1.148</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1457\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Wed, 27 Jan 2021   Pseudo R-squ.:                 0.05958\n",
       "Time:                        14:19:37   Log-Likelihood:                -861.60\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.483e-25\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.0659      0.067     15.922      0.000       0.935       1.197\n",
       "junk          -1.4166      0.137    -10.331      0.000      -1.685      -1.148\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula = \"\"\"CROSS_SELL_SUCCESS ~ junk\"\"\",\n",
    "                           data    = Apprentice_Chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model showed a very low R-squared but it also shows a P-value of 0.00 which means that it can be significant.\n",
    "<br>\n",
    "<br>\n",
    "Now we are going to create another model using all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REVENUE + \n",
      " TOTAL_MEALS_ORDERED + \n",
      " UNIQUE_MEALS_PURCH + \n",
      " CONTACTS_W_CUSTOMER_SERVICE + \n",
      " PRODUCT_CATEGORIES_VIEWED + \n",
      " AVG_TIME_PER_SITE_VISIT + \n",
      " MOBILE_NUMBER + \n",
      " CANCELLATIONS_BEFORE_NOON + \n",
      " CANCELLATIONS_AFTER_NOON + \n",
      " TASTES_AND_PREFERENCES + \n",
      " PC_LOGINS + \n",
      " MOBILE_LOGINS + \n",
      " WEEKLY_PLAN + \n",
      " EARLY_DELIVERIES + \n",
      " LATE_DELIVERIES + \n",
      " PACKAGE_LOCKER + \n",
      " REFRIGERATED_LOCKER + \n",
      " AVG_PREP_VID_TIME + \n",
      " LARGEST_ORDER_SIZE + \n",
      " MASTER_CLASSES_ATTENDED + \n",
      " MEDIAN_MEAL_RATING + \n",
      " AVG_CLICKS_PER_VISIT + \n",
      " TOTAL_PHOTOS_VIEWED + \n",
      " unknown + \n",
      " potential_male + \n",
      " potential_female + \n",
      " junk + \n",
      " personal + \n",
      " professional + \n",
      " TOTAL_MEALS_ORDERED_range + \n",
      " AVG_PREP_VID_TIME_range + \n",
      " CONTACTS_W_CUSTOMER_SERVICE_range + \n",
      " PRODUCT_CATEGORIES_VIEWED_range + \n",
      " CANCELLATIONS_BEFORE_NOON_range + \n",
      " CANCELLATIONS_AFTER_NOON_range + \n",
      " MOBILE_LOGINS_range + \n",
      " WEEKLY_PLAN_range + \n",
      " EARLY_DELIVERIES_range + \n",
      " LATE_DELIVERIES_range + \n",
      " LARGEST_ORDER_SIZE_range + \n",
      " MEDIAN_MEAL_RATING_range + \n",
      " MASTER_CLASSES_ATTENDED_range + \n",
      " REVENUE_range + \n"
     ]
    }
   ],
   "source": [
    "for val in Apprentice_Chef_data:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532696\n",
      "         Iterations 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:1354: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1421</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    37</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jan 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1517</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:24:17</td>      <th>  Log-Likelihood:    </th> <td> -777.20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.052e-38</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                         <td>   -1.0633</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REVENUE</th>                           <td>   -0.0001</td> <td>    0.000</td> <td>   -0.656</td> <td> 0.512</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_MEALS_ORDERED</th>               <td>    0.0028</td> <td>    0.007</td> <td>    0.421</td> <td> 0.673</td> <td>   -0.010</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNIQUE_MEALS_PURCH</th>                <td>   -0.0157</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CONTACTS_W_CUSTOMER_SERVICE</th>       <td>    0.0725</td> <td>    0.046</td> <td>    1.561</td> <td> 0.118</td> <td>   -0.019</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PRODUCT_CATEGORIES_VIEWED</th>         <td>   -0.0196</td> <td>    0.046</td> <td>   -0.426</td> <td> 0.670</td> <td>   -0.110</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_TIME_PER_SITE_VISIT</th>           <td>    0.0003</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>                     <td>    0.9529</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>         <td>    0.2331</td> <td>    0.071</td> <td>    3.269</td> <td> 0.001</td> <td>    0.093</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON</th>          <td>   -0.4566</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>            <td>    0.3505</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS</th>                         <td>    0.2609</td> <td>    0.162</td> <td>    1.612</td> <td> 0.107</td> <td>   -0.056</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_LOGINS</th>                     <td>   -0.2738</td> <td>    0.459</td> <td>   -0.597</td> <td> 0.551</td> <td>   -1.173</td> <td>    0.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WEEKLY_PLAN</th>                       <td>    0.0076</td> <td>    0.007</td> <td>    1.092</td> <td> 0.275</td> <td>   -0.006</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>                  <td>    0.1408</td> <td>    0.046</td> <td>    3.039</td> <td> 0.002</td> <td>    0.050</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LATE_DELIVERIES</th>                   <td>    0.0098</td> <td>    0.028</td> <td>    0.353</td> <td> 0.724</td> <td>   -0.045</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PACKAGE_LOCKER</th>                    <td>    0.0505</td> <td>    0.239</td> <td>    0.212</td> <td> 0.832</td> <td>   -0.417</td> <td>    0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>               <td>    0.4561</td> <td>    0.269</td> <td>    1.698</td> <td> 0.090</td> <td>   -0.070</td> <td>    0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_PREP_VID_TIME</th>                 <td>    0.0039</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LARGEST_ORDER_SIZE</th>                <td>   -0.0276</td> <td>    0.200</td> <td>   -0.138</td> <td> 0.890</td> <td>   -0.419</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MASTER_CLASSES_ATTENDED</th>           <td>   -0.1245</td> <td>    0.486</td> <td>   -0.256</td> <td> 0.798</td> <td>   -1.077</td> <td>    0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEDIAN_MEAL_RATING</th>                <td>    0.1402</td> <td>    0.606</td> <td>    0.232</td> <td> 0.817</td> <td>   -1.047</td> <td>    1.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_CLICKS_PER_VISIT</th>              <td>   -0.0154</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_PHOTOS_VIEWED</th>               <td>   -0.0003</td> <td>    0.000</td> <td>   -0.656</td> <td> 0.512</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unknown</th>                           <td>   -0.3249</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>                              <td>   -1.4350</td> <td> 4.24e+06</td> <td>-3.38e-07</td> <td> 1.000</td> <td>-8.32e+06</td> <td> 8.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal</th>                          <td>   -0.0459</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>professional</th>                      <td>    0.5063</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_male</th>                    <td>    0.2780</td> <td> 1.39e+05</td> <td> 2.01e-06</td> <td> 1.000</td> <td>-2.72e+05</td> <td> 2.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_female</th>                  <td>   -0.9941</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_MEALS_ORDERED_range</th>         <td>    0.8951</td> <td>    0.366</td> <td>    2.443</td> <td> 0.015</td> <td>    0.177</td> <td>    1.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_PREP_VID_TIME_range</th>           <td>    0.0163</td> <td>    0.131</td> <td>    0.125</td> <td> 0.900</td> <td>   -0.240</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CONTACTS_W_CUSTOMER_SERVICE_range</th> <td>   -1.0411</td> <td> 2.78e+24</td> <td>-3.75e-25</td> <td> 1.000</td> <td>-5.45e+24</td> <td> 5.45e+24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PRODUCT_CATEGORIES_VIEWED_range</th>   <td>   -1.0411</td> <td> 1.63e+24</td> <td>-6.38e-25</td> <td> 1.000</td> <td> -3.2e+24</td> <td>  3.2e+24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON_range</th>   <td>    0.1854</td> <td>    0.176</td> <td>    1.052</td> <td> 0.293</td> <td>   -0.160</td> <td>    0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON_range</th>    <td>    0.2835</td> <td>    0.405</td> <td>    0.699</td> <td> 0.484</td> <td>   -0.511</td> <td>    1.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_LOGINS_range</th>               <td>    1.7479</td> <td>    0.709</td> <td>    2.466</td> <td> 0.014</td> <td>    0.359</td> <td>    3.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WEEKLY_PLAN_range</th>                 <td>   -0.1509</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES_range</th>            <td>   -0.4059</td> <td>    0.208</td> <td>   -1.955</td> <td> 0.051</td> <td>   -0.813</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LATE_DELIVERIES_range</th>             <td>    0.0297</td> <td>    0.191</td> <td>    0.156</td> <td> 0.876</td> <td>   -0.344</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LARGEST_ORDER_SIZE_range</th>          <td>   -1.0411</td> <td> 5.59e+23</td> <td>-1.86e-24</td> <td> 1.000</td> <td> -1.1e+24</td> <td>  1.1e+24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MEDIAN_MEAL_RATING_range</th>          <td>   -1.0411</td> <td> 8.34e+23</td> <td>-1.25e-24</td> <td> 1.000</td> <td>-1.63e+24</td> <td> 1.63e+24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MASTER_CLASSES_ATTENDED_range</th>     <td>    0.4115</td> <td>    0.075</td> <td>    5.507</td> <td> 0.000</td> <td>    0.265</td> <td>    0.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REVENUE_range</th>                     <td>    0.2514</td> <td>    0.279</td> <td>    0.901</td> <td> 0.368</td> <td>   -0.296</td> <td>    0.799</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1421\n",
       "Method:                           MLE   Df Model:                           37\n",
       "Date:                Wed, 27 Jan 2021   Pseudo R-squ.:                  0.1517\n",
       "Time:                        17:24:17   Log-Likelihood:                -777.20\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.052e-38\n",
       "=====================================================================================================\n",
       "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "Intercept                            -1.0633        nan        nan        nan         nan         nan\n",
       "REVENUE                              -0.0001      0.000     -0.656      0.512      -0.001       0.000\n",
       "TOTAL_MEALS_ORDERED                   0.0028      0.007      0.421      0.673      -0.010       0.016\n",
       "UNIQUE_MEALS_PURCH                   -0.0157        nan        nan        nan         nan         nan\n",
       "CONTACTS_W_CUSTOMER_SERVICE           0.0725      0.046      1.561      0.118      -0.019       0.164\n",
       "PRODUCT_CATEGORIES_VIEWED            -0.0196      0.046     -0.426      0.670      -0.110       0.071\n",
       "AVG_TIME_PER_SITE_VISIT               0.0003        nan        nan        nan         nan         nan\n",
       "MOBILE_NUMBER                         0.9529        nan        nan        nan         nan         nan\n",
       "CANCELLATIONS_BEFORE_NOON             0.2331      0.071      3.269      0.001       0.093       0.373\n",
       "CANCELLATIONS_AFTER_NOON             -0.4566        nan        nan        nan         nan         nan\n",
       "TASTES_AND_PREFERENCES                0.3505        nan        nan        nan         nan         nan\n",
       "PC_LOGINS                             0.2609      0.162      1.612      0.107      -0.056       0.578\n",
       "MOBILE_LOGINS                        -0.2738      0.459     -0.597      0.551      -1.173       0.625\n",
       "WEEKLY_PLAN                           0.0076      0.007      1.092      0.275      -0.006       0.021\n",
       "EARLY_DELIVERIES                      0.1408      0.046      3.039      0.002       0.050       0.232\n",
       "LATE_DELIVERIES                       0.0098      0.028      0.353      0.724      -0.045       0.064\n",
       "PACKAGE_LOCKER                        0.0505      0.239      0.212      0.832      -0.417       0.518\n",
       "REFRIGERATED_LOCKER                   0.4561      0.269      1.698      0.090      -0.070       0.983\n",
       "AVG_PREP_VID_TIME                     0.0039        nan        nan        nan         nan         nan\n",
       "LARGEST_ORDER_SIZE                   -0.0276      0.200     -0.138      0.890      -0.419       0.364\n",
       "MASTER_CLASSES_ATTENDED              -0.1245      0.486     -0.256      0.798      -1.077       0.828\n",
       "MEDIAN_MEAL_RATING                    0.1402      0.606      0.232      0.817      -1.047       1.327\n",
       "AVG_CLICKS_PER_VISIT                 -0.0154        nan        nan        nan         nan         nan\n",
       "TOTAL_PHOTOS_VIEWED                  -0.0003      0.000     -0.656      0.512      -0.001       0.001\n",
       "unknown                              -0.3249        nan        nan        nan         nan         nan\n",
       "junk                                 -1.4350   4.24e+06  -3.38e-07      1.000   -8.32e+06    8.32e+06\n",
       "personal                             -0.0459        nan        nan        nan         nan         nan\n",
       "professional                          0.5063        nan        nan        nan         nan         nan\n",
       "potential_male                        0.2780   1.39e+05   2.01e-06      1.000   -2.72e+05    2.72e+05\n",
       "potential_female                     -0.9941        nan        nan        nan         nan         nan\n",
       "TOTAL_MEALS_ORDERED_range             0.8951      0.366      2.443      0.015       0.177       1.613\n",
       "AVG_PREP_VID_TIME_range               0.0163      0.131      0.125      0.900      -0.240       0.272\n",
       "CONTACTS_W_CUSTOMER_SERVICE_range    -1.0411   2.78e+24  -3.75e-25      1.000   -5.45e+24    5.45e+24\n",
       "PRODUCT_CATEGORIES_VIEWED_range      -1.0411   1.63e+24  -6.38e-25      1.000    -3.2e+24     3.2e+24\n",
       "CANCELLATIONS_BEFORE_NOON_range       0.1854      0.176      1.052      0.293      -0.160       0.531\n",
       "CANCELLATIONS_AFTER_NOON_range        0.2835      0.405      0.699      0.484      -0.511       1.078\n",
       "MOBILE_LOGINS_range                   1.7479      0.709      2.466      0.014       0.359       3.137\n",
       "WEEKLY_PLAN_range                    -0.1509        nan        nan        nan         nan         nan\n",
       "EARLY_DELIVERIES_range               -0.4059      0.208     -1.955      0.051      -0.813       0.001\n",
       "LATE_DELIVERIES_range                 0.0297      0.191      0.156      0.876      -0.344       0.403\n",
       "LARGEST_ORDER_SIZE_range             -1.0411   5.59e+23  -1.86e-24      1.000    -1.1e+24     1.1e+24\n",
       "MEDIAN_MEAL_RATING_range             -1.0411   8.34e+23  -1.25e-24      1.000   -1.63e+24    1.63e+24\n",
       "MASTER_CLASSES_ATTENDED_range         0.4115      0.075      5.507      0.000       0.265       0.558\n",
       "REVENUE_range                         0.2514      0.279      0.901      0.368      -0.296       0.799\n",
       "=====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~ REVENUE + \n",
    " TOTAL_MEALS_ORDERED + \n",
    " UNIQUE_MEALS_PURCH + \n",
    " CONTACTS_W_CUSTOMER_SERVICE + \n",
    " PRODUCT_CATEGORIES_VIEWED + \n",
    " AVG_TIME_PER_SITE_VISIT + \n",
    " MOBILE_NUMBER + \n",
    " CANCELLATIONS_BEFORE_NOON + \n",
    " CANCELLATIONS_AFTER_NOON + \n",
    " TASTES_AND_PREFERENCES + \n",
    " PC_LOGINS + \n",
    " MOBILE_LOGINS + \n",
    " WEEKLY_PLAN + \n",
    " EARLY_DELIVERIES + \n",
    " LATE_DELIVERIES + \n",
    " PACKAGE_LOCKER + \n",
    " REFRIGERATED_LOCKER + \n",
    " AVG_PREP_VID_TIME + \n",
    " LARGEST_ORDER_SIZE + \n",
    " MASTER_CLASSES_ATTENDED + \n",
    " MEDIAN_MEAL_RATING + \n",
    " AVG_CLICKS_PER_VISIT + \n",
    " TOTAL_PHOTOS_VIEWED + \n",
    " unknown + \n",
    " junk + \n",
    " personal + \n",
    " professional + \n",
    " potential_male + \n",
    " potential_female +\n",
    " TOTAL_MEALS_ORDERED_range + \n",
    " AVG_PREP_VID_TIME_range + \n",
    " CONTACTS_W_CUSTOMER_SERVICE_range + \n",
    " PRODUCT_CATEGORIES_VIEWED_range + \n",
    " CANCELLATIONS_BEFORE_NOON_range + \n",
    " CANCELLATIONS_AFTER_NOON_range + \n",
    " MOBILE_LOGINS_range + \n",
    " WEEKLY_PLAN_range + \n",
    " EARLY_DELIVERIES_range + \n",
    " LATE_DELIVERIES_range + \n",
    " LARGEST_ORDER_SIZE_range + \n",
    " MEDIAN_MEAL_RATING_range + \n",
    " MASTER_CLASSES_ATTENDED_range + \n",
    " REVENUE_range\"\"\",  data    = Apprentice_Chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows not so much improvement with only an R-square of 0.14. A lot of the P-values of the coefficients are not siginificant, after doing this we will see if the model improves.\n",
    "<br>\n",
    "<br>\n",
    "We create a new model using only significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.586456\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1441</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    17</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Jan 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.06609</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:28:33</td>      <th>  Log-Likelihood:    </th> <td> -855.64</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>9.475e-18</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                         <td>   -1.1939</td> <td> 8.39e+06</td> <td>-1.42e-07</td> <td> 1.000</td> <td>-1.64e+07</td> <td> 1.64e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>                     <td>    0.7457</td> <td>    0.169</td> <td>    4.412</td> <td> 0.000</td> <td>    0.414</td> <td>    1.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>         <td>    0.1990</td> <td>    0.061</td> <td>    3.278</td> <td> 0.001</td> <td>    0.080</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>            <td>    0.3192</td> <td>    0.129</td> <td>    2.484</td> <td> 0.013</td> <td>    0.067</td> <td>    0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS</th>                         <td>    0.2149</td> <td>    0.102</td> <td>    2.117</td> <td> 0.034</td> <td>    0.016</td> <td>    0.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_LOGINS</th>                     <td>   -0.1591</td> <td>    0.111</td> <td>   -1.431</td> <td> 0.152</td> <td>   -0.377</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>                  <td>    0.1198</td> <td>    0.043</td> <td>    2.760</td> <td> 0.006</td> <td>    0.035</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>               <td>    0.4367</td> <td>    0.201</td> <td>    2.176</td> <td> 0.030</td> <td>    0.043</td> <td>    0.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_PREP_VID_TIME</th>                 <td>    0.0020</td> <td>    0.002</td> <td>    1.091</td> <td> 0.275</td> <td>   -0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal</th>                          <td>    0.1927</td> <td>    0.119</td> <td>    1.617</td> <td> 0.106</td> <td>   -0.041</td> <td>    0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_male</th>                    <td>    0.5235</td> <td>    0.153</td> <td>    3.424</td> <td> 0.001</td> <td>    0.224</td> <td>    0.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>potential_female</th>                  <td>   -0.6299</td> <td>    0.209</td> <td>   -3.015</td> <td> 0.003</td> <td>   -1.039</td> <td>   -0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TOTAL_MEALS_ORDERED_range</th>         <td>    0.4360</td> <td>    0.236</td> <td>    1.845</td> <td> 0.065</td> <td>   -0.027</td> <td>    0.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_PREP_VID_TIME_range</th>           <td>   -0.1590</td> <td>    0.180</td> <td>   -0.886</td> <td> 0.376</td> <td>   -0.511</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CONTACTS_W_CUSTOMER_SERVICE_range</th> <td>   -1.1939</td> <td> 8.39e+06</td> <td>-1.42e-07</td> <td> 1.000</td> <td>-1.64e+07</td> <td> 1.64e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON_range</th>   <td>    0.2583</td> <td>    0.167</td> <td>    1.542</td> <td> 0.123</td> <td>   -0.070</td> <td>    0.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON_range</th>    <td>   -0.2325</td> <td>    0.163</td> <td>   -1.423</td> <td> 0.155</td> <td>   -0.553</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES_range</th>            <td>   -0.3664</td> <td>    0.197</td> <td>   -1.860</td> <td> 0.063</td> <td>   -0.752</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LATE_DELIVERIES_range</th>             <td>    0.1293</td> <td>    0.157</td> <td>    0.825</td> <td> 0.410</td> <td>   -0.178</td> <td>    0.437</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1441\n",
       "Method:                           MLE   Df Model:                           17\n",
       "Date:                Wed, 27 Jan 2021   Pseudo R-squ.:                 0.06609\n",
       "Time:                        17:28:33   Log-Likelihood:                -855.64\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 9.475e-18\n",
       "=====================================================================================================\n",
       "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "Intercept                            -1.1939   8.39e+06  -1.42e-07      1.000   -1.64e+07    1.64e+07\n",
       "MOBILE_NUMBER                         0.7457      0.169      4.412      0.000       0.414       1.077\n",
       "CANCELLATIONS_BEFORE_NOON             0.1990      0.061      3.278      0.001       0.080       0.318\n",
       "TASTES_AND_PREFERENCES                0.3192      0.129      2.484      0.013       0.067       0.571\n",
       "PC_LOGINS                             0.2149      0.102      2.117      0.034       0.016       0.414\n",
       "MOBILE_LOGINS                        -0.1591      0.111     -1.431      0.152      -0.377       0.059\n",
       "EARLY_DELIVERIES                      0.1198      0.043      2.760      0.006       0.035       0.205\n",
       "REFRIGERATED_LOCKER                   0.4367      0.201      2.176      0.030       0.043       0.830\n",
       "AVG_PREP_VID_TIME                     0.0020      0.002      1.091      0.275      -0.002       0.006\n",
       "personal                              0.1927      0.119      1.617      0.106      -0.041       0.426\n",
       "potential_male                        0.5235      0.153      3.424      0.001       0.224       0.823\n",
       "potential_female                     -0.6299      0.209     -3.015      0.003      -1.039      -0.220\n",
       "TOTAL_MEALS_ORDERED_range             0.4360      0.236      1.845      0.065      -0.027       0.899\n",
       "AVG_PREP_VID_TIME_range              -0.1590      0.180     -0.886      0.376      -0.511       0.193\n",
       "CONTACTS_W_CUSTOMER_SERVICE_range    -1.1939   8.39e+06  -1.42e-07      1.000   -1.64e+07    1.64e+07\n",
       "CANCELLATIONS_BEFORE_NOON_range       0.2583      0.167      1.542      0.123      -0.070       0.586\n",
       "CANCELLATIONS_AFTER_NOON_range       -0.2325      0.163     -1.423      0.155      -0.553       0.088\n",
       "EARLY_DELIVERIES_range               -0.3664      0.197     -1.860      0.063      -0.752       0.020\n",
       "LATE_DELIVERIES_range                 0.1293      0.157      0.825      0.410      -0.178       0.437\n",
       "=====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~   \n",
    " MOBILE_NUMBER + \n",
    " CANCELLATIONS_BEFORE_NOON +  \n",
    " TASTES_AND_PREFERENCES + \n",
    " PC_LOGINS + \n",
    " MOBILE_LOGINS + \n",
    " EARLY_DELIVERIES +  \n",
    " REFRIGERATED_LOCKER + \n",
    " AVG_PREP_VID_TIME + \n",
    " personal + \n",
    " potential_male + \n",
    " potential_female +\n",
    " TOTAL_MEALS_ORDERED_range + \n",
    " AVG_PREP_VID_TIME_range + \n",
    " CONTACTS_W_CUSTOMER_SERVICE_range + \n",
    " CANCELLATIONS_BEFORE_NOON_range + \n",
    " CANCELLATIONS_AFTER_NOON_range +  \n",
    " EARLY_DELIVERIES_range + \n",
    " LATE_DELIVERIES_range\"\"\",  data    = Apprentice_Chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-square did not improve but we found some variables that are significant.\n",
    "<br>\n",
    "<br>\n",
    "Now we create different dictionaries with potential models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH', 'CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                   'PRODUCT_CATEGORIES_VIEWED', 'AVG_TIME_PER_SITE_VISIT',\n",
    "                   'MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON',\n",
    "                   'TASTES_AND_PREFERENCES', 'PC_LOGINS', 'MOBILE_LOGINS', 'WEEKLY_PLAN', \n",
    "                  'EARLY_DELIVERIES', 'LATE_DELIVERIES', 'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER',\n",
    "                  'AVG_PREP_VID_TIME', 'LARGEST_ORDER_SIZE', 'MASTER_CLASSES_ATTENDED', 'MEDIAN_MEAL_RATING',\n",
    "                  'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED', 'unknown', 'junk', 'personal', 'professional',\n",
    "                  'potential_male', 'potential_female'],\n",
    " \n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES', \n",
    "                  'AVG_PREP_VID_TIME', 'junk', 'professional', 'potential_male', 'potential_female'],\n",
    "    \n",
    "    \n",
    " # significant variables only (set 2)\n",
    " 'logit_sig_2'  : ['MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON','MOBILE_LOGINS', 'EARLY_DELIVERIES',\n",
    "                  'AVG_PREP_VID_TIME', 'personal', 'professional', 'potential_male', 'potential_female'],\n",
    " \n",
    " # significant variables only (set 3)\n",
    " 'logit_sig_3'  : ['MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON','MOBILE_LOGINS', 'EARLY_DELIVERIES',\n",
    "                  'AVG_PREP_VID_TIME', 'personal', 'junk', 'potential_male', 'potential_female']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7354\n",
      "Testing  ACCURACY: 0.7228\n",
      "0.6266\n"
     ]
    }
   ],
   "source": [
    "# train/test split with one set of significant variables\n",
    "Apprentice_Chef_data   =  Apprentice_Chef.loc[ : , candidate_dict['logit_sig_2']]\n",
    "Apprentice_Chef_target =  Apprentice_Chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# Split the data into Training and Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            Apprentice_Chef_data,\n",
    "            Apprentice_Chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = Apprentice_Chef_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            max_iter = 1000,\n",
    "                            random_state = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(X_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(X_test, y_test).round(4) # accuracy\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking all the different dictionaries created, the one that does not have a big gap between the training and testing is 'logit_sig_2'. So we are going to use this set of variables with different models to check if the AUC can be improved.\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /r><br>\n",
    "<h4>Balancing the outcome variable</h4>\n",
    "By upsampling the minority class, the dataset will be balanced. This will allow us to work better with a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1321\n",
       "0    1321\n",
       "Name: CROSS_SELL_SUCCESS, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "Apprentice_Chef_majority = Apprentice_Chef[Apprentice_Chef.CROSS_SELL_SUCCESS==1]\n",
    "Apprentice_Chef_minority = Apprentice_Chef[Apprentice_Chef.CROSS_SELL_SUCCESS==0]\n",
    " \n",
    "# Upsample minority class\n",
    "Apprentice_Chef_minority_upsampled = resample(Apprentice_Chef_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=1321,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "Apprentice_Chef_upsampled = pd.concat([Apprentice_Chef_majority, Apprentice_Chef_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "Apprentice_Chef_upsampled.CROSS_SELL_SUCCESS.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the same number of 0's and 1's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6774\n",
      "Testing  ACCURACY: 0.6475\n",
      "0.6475\n"
     ]
    }
   ],
   "source": [
    "# train/test split with one set of significant variables\n",
    "Apprentice_Chef_data   =  Apprentice_Chef_upsampled.loc[ : , candidate_dict['logit_sig_2']]\n",
    "Apprentice_Chef_target =  Apprentice_Chef_upsampled.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# Split the data into Training and Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            Apprentice_Chef_data,\n",
    "            Apprentice_Chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = Apprentice_Chef_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            max_iter = 1000,\n",
    "                            random_state = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(X_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(X_test, y_test).round(4) # accuracy\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing it with the previous model, now that we are using balanced data, the training and testing has become more real and the AUC score of the model slightly improved.\n",
    "<br>\n",
    "<br>\n",
    "We will continue with the exploration of different models.<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Classification Tree</h4>\n",
    "This first decision tree is a full tree using the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 0.9985\n",
      "Full Tree Testing ACCURACY : 0.7912\n",
      "Full Tree AUC Score: 0.7913\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(X_train,\n",
    "                                                    y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(X_test,\n",
    "                                                    y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(X_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model really improved in AUC score, increasing from 0.64 to 0.79 \n",
    "On the other hand the training and testing accuracy gap increased. So we will continue exploring other models to see if the AUC score increases even more and the gap between the data decreases.\n",
    "<hr>\n",
    "<h4>Pruned Classification Tree</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7173\n",
      "Testing  ACCURACY: 0.6853\n",
      "AUC Score        : 0.6855\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 8,\n",
    "                                     min_samples_leaf = 20,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(X_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(X_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning the tree caused a reduction of the AUC score but the gap between training and testing has been reduced.\n",
    "<hr>\n",
    "<h4>KNN</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 1\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "opt_neighbors = optimal_neighbors(X_data        = Apprentice_Chef_data,\n",
    "                                  y_data        = Apprentice_Chef_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.9985\n",
      "Testing  ACCURACY: 0.8245\n",
      "AUC Score        : 0.8246\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(Apprentice_Chef_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "X_scaled     = scaler.transform(Apprentice_Chef_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_scaled_df  = pd.DataFrame(X_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            X_scaled_df,\n",
    "            Apprentice_Chef_target,\n",
    "            random_state = 219,\n",
    "            test_size = 0.25,\n",
    "            stratify = Apprentice_Chef_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(X_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(X_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems to continue to overfit but the AUC score increased significantly. So far, this is the best model to use.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Decision Tree with Tuned Hyperparameters</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-99f3cab859aa>:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  depth_space     = pd.np.arange(1, 10, 1)\n",
      "<ipython-input-42-99f3cab859aa>:5: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  leaf_space      = pd.np.arange(1, 120, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'splitter': 'random', 'min_samples_leaf': 46, 'max_depth': 8, 'criterion': 'entropy'}\n",
      "Tuned Training AUC: 0.6589\n"
     ]
    }
   ],
   "source": [
    "# declaring a hyperparameter space\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space  = ['best', 'random']\n",
    "depth_space     = pd.np.arange(1, 10, 1)\n",
    "leaf_space      = pd.np.arange(1, 120, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid,\n",
    "                                   cv                    = 3,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219,\n",
    "                                   scoring = make_scorer(roc_auc_score,\n",
    "                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(Apprentice_Chef_data, Apprentice_Chef_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.6885\n",
      "Testing  ACCURACY: 0.6536\n",
      "AUC Score        : 0.6536\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = tuned_tree_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "model_fit=tree_tuned.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(X_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(X_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from this score that is the highest AUC score so far. Also, the accuracy between the training and testing is not a big gap which can mean that the model is functioning properly and it is not overfitting.\n",
    "<br>\n",
    "<br>\n",
    "We create the confusion matrix to see the outcome of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 280\n",
      "False Positives: 50\n",
      "False Negatives: 103\n",
      "True Positives : 228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 8,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.787\n",
      "Testing  ACCURACY: 0.705\n",
      "AUC Score        : 0.705\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(X_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score from this model drops from the one we had before and the gap in the data is much higher.\n",
    "<hr>\n",
    "<h4>Final Table with results of the selected model<h/4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model     Training Accuracy  Testing Accuracy   AUC Score      TN, FP, FN, TP\n",
      "-----         ---------      --------------    -----------     ---------------\n",
      "Tuned Tree   0.9278              0.7685          0.7687        (280, 50, 103, 228)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model     Training Accuracy  Testing Accuracy   AUC Score      TN, FP, FN, TP\n",
    "-----         ---------      --------------    -----------     ---------------\n",
    "Tuned Tree   {tree_tuned_train_score}              {tree_tuned_test_score}          {tree_tuned_auc}        {tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Tuned Tree'],\n",
    "           \n",
    "    'AUC Score' : [tree_tuned_auc, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [tree_tuned_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [tree_tuned_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "<h2>3. Conclusion</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning, the data was not showing to be fitting to any model. Analyzing it and viewing the correlation of each variable towards CROSS_SELL_SUCCESS allowed to understand the problem.\n",
    "By balancing the data and doing oversampling it allowed for the models to create better results. \n",
    "In the end the best model turned out to be the Tuned Tree with an AUC score of 0.9304, training accuracy of 0.9112, testing accuracy 0f 0.9304 and running with the variables in the dictionary of 'logit_sig_2' which includes the following: 'MOBILE_NUMBER' , 'CANCELLATIONS_BEFORE_NOON','MOBILE_LOGINS', 'EARLY_DELIVERIES',\n",
    "'AVG_PREP_VID_TIME', 'personal', 'professional', 'potential_male', 'potential_female'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
